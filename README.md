# 3Då¹¶è¡Œè®­ç»ƒæ¡†æ¶

<div align="center">

**å·¥ä¸šçº§å¤§è¯­è¨€æ¨¡å‹3Då¹¶è¡Œè®­ç»ƒç³»ç»Ÿ**

æ”¯æŒ Data Parallel (DP) + Tensor Parallel (TP) + Pipeline Parallel (PP)

[å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [æ–‡æ¡£](docs/USAGE_GUIDE.md) â€¢ [ç¤ºä¾‹](examples/)

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

---

## âœ¨ æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|-----|------|
| ğŸ¯ **å®Œæ•´3Då¹¶è¡Œ** | DP + TP (Megatron) + PP (GPipe/1F1B) |
| âš¡ **é«˜æ€§èƒ½** | æ¥è¿‘ç†è®ºåŠ é€Ÿæ¯”ï¼Œæ”¯æŒæ··åˆç²¾åº¦ |
| ğŸ”§ **æ˜“ç”¨æ€§** | ç»Ÿä¸€å…¥å£è„šæœ¬ï¼Œä¸€é”®å¯åŠ¨ |
| ğŸ“¦ **å¼€ç®±å³ç”¨** | é¢„é…ç½®æ¨¡å‹ï¼Œè‡ªåŠ¨ä¼˜åŒ– |
| ğŸŒ **å¤šèŠ‚ç‚¹** | æ”¯æŒå•æœºå¤šå¡å’Œå¤šæœºå¤šå¡ |
| ğŸ” **å¯è§‚æµ‹** | å®Œæ•´æ—¥å¿—ã€ç›‘æ§ã€æ£€æŸ¥ç‚¹ |

## ğŸ“ é¡¹ç›®ç»“æ„

```
3d_parallel_training/
â”œâ”€â”€ train.py                   # æ ‡å‡†è®­ç»ƒè„šæœ¬
â”‚
â”œâ”€â”€ megatron_model.py          # Megatronæ¨¡å‹
â”‚
â”œâ”€â”€ scripts/                   # å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ run_3d_parallel.sh
â”‚   â”œâ”€â”€ run_megatron.sh
â”‚   â”œâ”€â”€ run_deepspeed.sh
â”‚   â””â”€â”€ run_multinode.sh
â”‚
â”œâ”€â”€ configs/                   # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ models/                # æ¨¡å‹é…ç½®
â”‚   â”‚   â”œâ”€â”€ small.yaml
â”‚   â”‚   â”œâ”€â”€ medium.yaml
â”‚   â”‚   â””â”€â”€ large.yaml
â”‚   â””â”€â”€ deepspeed/             # DeepSpeedé…ç½®
â”‚       â”œâ”€â”€ zero2.json
â”‚       â””â”€â”€ zero3.json
â”‚
â”œâ”€â”€ src/                     # å·¥å…·
â”‚   â”œâ”€â”€ monitor.py
â”‚
â”œâ”€â”€ docs/                      # æ–‡æ¡£
â”‚   â””â”€â”€ USAGE_GUIDE.md
â”‚
â””â”€â”€ examples/                  # ç¤ºä¾‹ (TODO)
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£…PyTorch (æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt

# å¿«é€Ÿæµ‹è¯•
bash tools/quick_test.sh
```


### 2. ç›‘æ§è®­ç»ƒ

```bash
# å®æ—¶ç›‘æ§
python tools/monitor.py

# æŸ¥çœ‹æ—¥å¿—
tail -f output_*/train.log

# GPUçŠ¶æ€
watch -n 1 nvidia-smi
```

```

###  å¤šèŠ‚ç‚¹è®­ç»ƒ

**èŠ‚ç‚¹0 (ä¸»èŠ‚ç‚¹)**:
```bash
NUM_NODES=2 NODE_RANK=0 MASTER_ADDR="192.168.1.100" \
bash scripts/run_multinode.sh
```

**èŠ‚ç‚¹1**:
```bash
NUM_NODES=2 NODE_RANK=1 MASTER_ADDR="192.168.1.100" \
bash scripts/run_multinode.sh
```

## âš™ï¸ é…ç½®æŒ‡å—

### å¹¶è¡Œç­–ç•¥é€‰æ‹©

```python
# å†³ç­–æ ‘
if æ¨¡å‹ < 1B:
    ä½¿ç”¨ DDP (--mode simple)
elif æ¨¡å‹ < 10B:
    ä½¿ç”¨ DP+TP (--mode 3d --tp 2)
elif æ¨¡å‹ < 100B:
    ä½¿ç”¨ DP+TP+PP (--mode 3d --tp 4 --pp 2)
else:
    ä½¿ç”¨ 3D+ZeRO3 (--mode deepspeed --zero-stage 3)
```

### å‚æ•°å»ºè®®

| å‚æ•° | å°æ¨¡å‹ | ä¸­æ¨¡å‹ | å¤§æ¨¡å‹ |
|-----|--------|--------|--------|
| `--tp` | 1 | 2 | 4-8 |
| `--pp` | 1 | 2 | 2-4 |
| `--batch-size` | 8-16 | 4-8 | 2-4 |
| `--zero-stage` | 0 | 2 | 3 |

## ğŸ“– æ–‡æ¡£

- **[USAGE_GUIDE.md](docs/USAGE_GUIDE.md)** - å®Œæ•´ä½¿ç”¨æŒ‡å—
  - è¯¦ç»†çš„å¹¶è¡Œç­–ç•¥è¯´æ˜
  - å¤šèŠ‚ç‚¹è®­ç»ƒé…ç½®
  - æ€§èƒ½ä¼˜åŒ–æŠ€å·§
  - å¸¸è§é—®é¢˜è§£ç­”

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md)

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE)

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®å‚è€ƒäº†ï¼š
- [Megatron-LM](https://github.com/NVIDIA/Megatron-LM)
- [DeepSpeed](https://github.com/microsoft/DeepSpeed)
- [PyTorch](https://pytorch.org/)

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStarï¼â­**

Made with â¤ï¸ for the AI community

</div>
